{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _*Repetition code for up to 15 qubits*_\n",
    "\n",
    "For more information about how to use the IBM Q experience (QX), consult the [tutorials](https://quantumexperience.ng.bluemix.net/qstage/#/tutorial?sectionId=c59b3710b928891a1420190148a72cce&pageIndex=0), or check out the [community](https://quantumexperience.ng.bluemix.net/qstage/#/community).\n",
    "\n",
    "***\n",
    "### Contributors\n",
    "James R. Wootton, University of Basel\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Introduction\n",
    "\n",
    "The repetition code is a classical error correcting code, with which a collection of noisy bits can be used to store a bit value with arbitrarily low noise.\n",
    "\n",
    "The code can also be interpreted as a quantum error correcting code, in which the noisy bits are replaced by noisy qubits. Such a code can be used to store a *bit* with arbitrarily low noise. However, due to the limited set of errors that can be detected and corrected, it cannot fully protect a *qubit*.\n",
    "\n",
    "Despite this fact, the repetition code based on qubits uses essentially the same resources and techniques as other quantum codes. It can therefore serve as a prelimary test of quantum error correction. An introduction to these concepts for a general audience can be found [here](http://decodoku.blogspot.ch/2016/01/what-is-error-correction-what-is.html).\n",
    "\n",
    "Until now, the most extensive experiments of quantum repetition codes were implemented a few years ago by the team at Google/UCSB.\n",
    "\n",
    "[J. Kelly et al., Nature **519**, *66â€“69* (2015)](https://www.nature.com/nature/journal/v519/n7541/full/nature14270.html)\n",
    "\n",
    "The largest repetition code in this experiment used 5 qubits to store data (we call these *code qubits*), and an additional 4 *ancilla qubits* to mediate measurements. In this notebook we will use the 16 qubit device *ibmqx3* to implement codes of a variety of sizes, including some larger than those in the Google/UCSB experiment.\n",
    "\n",
    "The number of code qubits in our experiments will be denoted *d*. The number of ancilla qubits in a repetition code is always *d-1*, one less than that of code qubits.\n",
    "\n",
    "We will also use an additional qubit that is not part of the code, to compare storing a bit in a code with storing it in a single qubit. The total number of qubits needed is therefore *2d*. We will consider codes for *d=3...8*.\n",
    "\n",
    "In each case we will do a single round of ancilla-assisted syndrome measurement followed by direct measurement of all qubits. This allows us to read out the value of the stored bit, as well as clues about errors that it may have suffered. Using this information, we can try to correct for the effects of the errors and recover the original value of the stored bit. By looking at how often this process succeeds, we will be able to see how well the system implements quantum error correction.\n",
    "\n",
    "The conditions under which we will declare the system as able to successfully implement the repetion code will be those set out in,\n",
    "\n",
    "[J. R. Wootton, A. Peter, J. R. Winkler, D. Loss, arXiv:1608.05053 (2016)](https://arxiv.org/abs/1608.05053).\n",
    "\n",
    "The aim of this study is to look at the properties of the repetion code when run using the 16 qubit *ibmqx3* device. A paper based on the results from this study can be found [here](https://arxiv.org/abs/1709.00990).\n",
    "\n",
    "Note that full results from both the *ibmqx3* device and simulator are alogside this notebook. This notebook can be used to analyze these pre-existing results, or to obtain and analyze new results. The outputs currently in this notebook come from analysis of the results from *ibmqx3*.\n",
    "\n",
    "In the program, the qubits in the register are labelled according to their address on the chip. The information can be found [here](https://github.com/IBM/qiskit-qx-info/tree/master/backends/ibmqx3).\n",
    "\n",
    "    1---2---3---4---5   6---7---8\n",
    "    |       |   |   |   |   |   |\n",
    "    0--15--14--13--12--11--10---9\n",
    "\n",
    "Lines in this diagram denote the possibility of a CNOT between the corresponding qubits.\n",
    "\n",
    "Qubits in the repetition code alternate between code and ancilla qubits. The single qubit is placed at the end of the line. For the case of d=8, the layout of these qubits will be as follows.\n",
    "\n",
    "    c2--a1--c1--a0--c0   s--c7--a6\n",
    "     |       |   |   |   |   |   |\n",
    "    a2--c3--a3--c4--a4--c5--a5--c6\n",
    " \n",
    "The address of code qubit c$n$ therefore $(5-2n)$%$16$.\n",
    "\n",
    "The address of ancilla qubit a$n$ is $(4-2n)$%$16$.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Set Up\n",
    "\n",
    "First we set up things required to run things using QISKit, and on the Quantum Experience.\n",
    "\n",
    "Set up intructions can be found in the [IBM SDK](https://github.com/QISKit/qiskit-sdk-py/).\n",
    "\n",
    "For more information about how to use the IBM Quantum experience, check out the [tutorials](https://quantumexperience.ng.bluemix.net/qstage/#/tutorial?sectionId=c59b3710b928891a1420190148a72cce&pageIndex=0), and the [community](https://quantumexperience.ng.bluemix.net/qstage/#/community)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qiskit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f688df2adec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../qiskit-sdk-py/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumProgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiskit'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../qiskit-sdk-py/\")\n",
    "from qiskit import QuantumProgram\n",
    "import Qconfig\n",
    "# for visualization\n",
    "from tools.visualization import plot_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import a few standard things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, json, copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3 - Functions\n",
    "\n",
    "The running of jobs and processing of data is handled by the following functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *AddError*\n",
    "\n",
    "Though our aim is to run on a real quantum device, a simulator can be used to make sure all is working as it should. There will be no errors in this case, so we will have to add in some fake ones.\n",
    "\n",
    "This function checks whether a simulator is being used. If so, it adds a rotation around the x axis as a stand-in for errors.\n",
    "\n",
    "The rotation chosen depends on the bit value stored in the code. The angle of rotation for stored *0* is half that for *1*. The reason is that realistic noise in the device has a bias towards transitions from *1* to *0*. Our choice of rotations serves as a simplistic way to obtain similar behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddError (script,q,num,simulator,bit):\n",
    "    \n",
    "    # errors are rotations around the x axis by a fraction of pi\n",
    "    # this fraction is twice as large for qubits initially in state 1\n",
    "    \n",
    "    fracAncilla = 0.05\n",
    "    \n",
    "    fracCode = fracAncilla\n",
    "    if (bit==1):\n",
    "        fracCode = fracCode*2\n",
    "\n",
    "    \n",
    "    # if the code is simulated add these rotations for error like effects\n",
    "    if (simulator):\n",
    "        for address in range(0,num-1,2): # code qubits\n",
    "            script.u3(fracCode * math.pi, 0.0, 0.0, q[address])\n",
    "        for address in range(1,num-1,2): # ancilla qubits\n",
    "            script.u3(fracAncilla * math.pi, 0.0, 0.0, q[address])\n",
    "        script.u3(fracCode * math.pi, 0.0, 0.0, q[num-1]) # single qubit\n",
    "                \n",
    "        script.barrier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *AddCnot*\n",
    "\n",
    "The input specifies control and target qubits for a CNOT gates.\n",
    "\n",
    "The function implements the CNOT if it is allowed by the device used. If the CNOT is not directly possible, but one with control and target interchanged can be done, conjugation by Hadamards is performed. Otherwise it will print an error.\n",
    "\n",
    "For a simulator, all things are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddCnot(repetitionScript,q,control,target,simulator):\n",
    "    \n",
    "    # set the coupling map ()\n",
    "    # b in coupling_map[a] means a CNOT with control qubit a and target qubit b can be implemented\n",
    "    # note that is is not just copy and pasted from https://github.com/IBM/qiskit-qx-info/tree/master/backends/ibmqx3\n",
    "    coupling_map = {0: [1], 1: [2], 2: [3], 3: [14], 4: [3, 5], 5: [], 6: [7, 11], 7: [10], 8: [7], 9: [10, 8], 10:[], 11: [10], 12: [5, 11, 13], 13: [4, 14], 14:[], 15: [0, 14]}\n",
    "    \n",
    "    # if such a CNOT is directly possible, we do it\n",
    "    if ( target in coupling_map[control] or simulator):\n",
    "        repetitionScript.cx(q[control], q[target])\n",
    "    # if it can be done the other way round we conjugate with Hadamards\n",
    "    elif ( control in coupling_map[target] ):\n",
    "        repetitionScript.h(q[control])\n",
    "        repetitionScript.h(q[target])\n",
    "        repetitionScript.cx(q[target], q[control])\n",
    "        repetitionScript.h(q[control])\n",
    "        repetitionScript.h(q[target])\n",
    "    else:\n",
    "        print('Qubits ' + str(control) + ' and ' + str(target) + ' cannot be entangled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *GetAddress*\n",
    "\n",
    "Given a code qubit specified by input *codeQubit* this function gives the address of that qubit in the register. For the ancillas either side, use an offset of *+1* or *-1*.\n",
    "\n",
    "For *codeQubit=0* only *offset=1* gives a valid ancilla. For *codeQubit=d-1* (the last one) *offset=-1* gives the last ancilla and *offset=1* gives the qubit that is trying to store the bit value on its own.\n",
    "\n",
    "For a simulator we don't bother with the coupling graph, so things are different and simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetAddress (codeQubit,offset,simulator):\n",
    "    \n",
    "    if (simulator):\n",
    "        address = 2*codeQubit + offset\n",
    "    else:\n",
    "        address = (5-2*codeQubit-offset)%16\n",
    "    \n",
    "    return address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *RunRepetition*\n",
    "\n",
    "This function takes a specification for a repetition code, runs it and then returns the result.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "* *bit* - Bit value to be stored in the repetition code. If it is not *1*, it will be treated as *0*.\n",
    "    \n",
    "* *d* - Number of code qubits\n",
    "\n",
    "* *device* - The backend device on which the job will be run. This should be 'ibmqx3', 'local_qasm_simulator' or 'ibmqx_qasm_simulator'.\n",
    "\n",
    "Output:\n",
    "\n",
    "* *results* - Dictionary with bit strings as keys and the fraction of times that result occurred as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RunRepetition(bit,d,device):\n",
    "    \n",
    "    # set the number of shots to use on the backend\n",
    "    shots = 8192\n",
    "    \n",
    "    # determine whether a simulator is used\n",
    "    simulator = (device!='ibmqx3')\n",
    "    \n",
    "    # if the simulator is used, we declare the minimum number of qubits required\n",
    "    if (simulator):\n",
    "        num = 2*d\n",
    "    # for the real device there are always 16\n",
    "    else:\n",
    "        num = 16\n",
    "        \n",
    "    # now to set up the quantum program (QASM)\n",
    "    Q_program = QuantumProgram()\n",
    "    Q_program.set_api(Qconfig.APItoken, Qconfig.config[\"url\"]) # set the APIToken and API url\n",
    "    # declare register of 5 qubits\n",
    "    q = Q_program.create_quantum_register(\"q\", num)\n",
    "    # declare register of 5 classical bits to hold measurement results\n",
    "    c = Q_program.create_classical_register(\"c\", num)\n",
    "    # create circuit\n",
    "    repetitionScript = Q_program.create_circuit(\"repetitionScript\", [q], [c])   \n",
    "    \n",
    "    \n",
    "    # now we insert all the quantum gates to be applied\n",
    "    # a barrier is inserted between each section of the code to prevent the complilation doing things we don't want it to\n",
    "    \n",
    "    # the stored bit is initialized by repeating it accross all code qubits same state\n",
    "    # since qubits are automatically initialized as 0, we just need to do Xs if b=1\n",
    "    if (bit==1):\n",
    "        for codeQubit in range(d):\n",
    "            repetitionScript.x( q[GetAddress(codeQubit,0,simulator)] )\n",
    "        # also do it for the single qubit on the end for comparision\n",
    "        repetitionScript.x( q[GetAddress(d-1,1,simulator)] )\n",
    "       \n",
    "    repetitionScript.barrier()\n",
    "    \n",
    "    # if the code is simulated add rotations for error like effects (and a barrier)\n",
    "    AddError(repetitionScript,q,num,simulator,bit)\n",
    "    \n",
    "    # we then start the syndrome measurements by doing CNOTs between each code qubit and the next ancilla along the line\n",
    "    for codeQubit in range(d-1):\n",
    "        AddCnot(repetitionScript,q,GetAddress(codeQubit,0,simulator),GetAddress(codeQubit,1,simulator),simulator)\n",
    "    repetitionScript.barrier()\n",
    "    \n",
    "    # if the code is simulated add rotations for error like effects (and a barrier)\n",
    "    AddError(repetitionScript,q,num,simulator,bit)\n",
    "    \n",
    "    # next we perform CNOTs between each code qubit and the previous ancilla along the line\n",
    "    for codeQubit in range(1,d):\n",
    "        AddCnot(repetitionScript,q,GetAddress(codeQubit,0,simulator),GetAddress(codeQubit,-1,simulator),simulator)\n",
    "    repetitionScript.barrier()\n",
    "    \n",
    "    # if the code is simulated add rotations for error like effects (and a barrier)\n",
    "    AddError(repetitionScript,q,num,simulator,bit)\n",
    "    \n",
    "    # all qubits are then measured\n",
    "    for address in range(num):\n",
    "        repetitionScript.measure(q[address], c[address])\n",
    "        \n",
    "    # set the APIToken and API url\n",
    "    Q_program.set_api(Qconfig.APItoken, Qconfig.config[\"url\"])\n",
    "    \n",
    "    # run the job until actual results are given\n",
    "    dataNeeded = True\n",
    "    while dataNeeded:\n",
    "            \n",
    "        # compile and run the qasm\n",
    "        executedJob = Q_program.execute([\"repetitionScript\"], backend=device, shots = shots, max_credits = 5, wait=5, timeout=600, silent=False)  \n",
    "        # extract data\n",
    "        results = executedJob.get_counts(\"repetitionScript\")\n",
    "        \n",
    "        # see if it really is data\n",
    "        if ('status' not in results.keys()):\n",
    "            dataNeeded = False\n",
    "        \n",
    "    \n",
    "    # the raw data states the number of runs for which each outcome occurred\n",
    "    # we convert this to fractions before output.\n",
    "    for key in results.keys():\n",
    "        results[key] = results[key]/shots\n",
    "    \n",
    "    # return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *AddProbToResults*\n",
    "\n",
    "The inputs are a probability *prob* for a given bit string *string* that is to be added to a dictionary *results*. The probability is added to the previous value for that bit string if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddProbToResults(prob,string,results):\n",
    "    \n",
    "    if string not in results.keys():\n",
    "        results[string] = 0\n",
    "    \n",
    "    results[string] += prob\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *CalculateError*\n",
    "\n",
    "The job of this function is to determine the total probability that the decoding fails when the encoded bit value is that specified by the input *encodedBit*, given the look up table in *results*. The way in which this is done is depends on the decoding procedure, which we will now explain.\n",
    "\n",
    "The decoder uses lookup tables, given by the input *results*. This is a pair of dictionaries, one for each possible value of the encoded bit, with bit strings as keys and probabilties of the form\n",
    "\n",
    "$$result[encodedBit][string] = P(\\,string\\,|\\,encodedBit\\,).$$\n",
    "\n",
    "Suppose the decoder were to receive an output *string* from a single run of the code with unknown initial value. The goal is then to deduce the most likely value of the encoded bit. This can be done using\n",
    "\n",
    "$$P(\\,encodedBit\\,|\\,string\\,) = \\frac{P(\\,string\\,|\\,encodedBit\\,) \\,\\times\\, P(\\,encodedBit\\,)}{P(\\,string\\,|\\,0\\,) + P(\\,string\\,|\\,1)\\,}.$$\n",
    "\n",
    "Assuming $P(\\,encodedBit\\,)=0.5$, with no bias towards *0* or *1*, $P(\\,encodedBit\\,|\\,string\\,)$ is simply proportional to $P(\\,string\\,|\\,encodedBit\\,)$. We can therefore decode by simply looking at which lookup table has the highest value for *string*. The corresponding encoded bit value is taken to be *decodedBit*, the value that the decoder assumes it that of the encoded bit.\n",
    "\n",
    "For example, consider a *d=3* code for which we only look at the output from the code qubits. Given a simple error model, we might expect results of the following form when *encodedBit=0*.\n",
    "\n",
    "    result[0] = \n",
    "    {'000': 0.669, '001': 0.1, '010': 0.1, '100': 0.1, '110': 0.01, '101': 0.01, '011':0.01, '111':0.001}\n",
    "\n",
    "Similarly for *encodedBit=1*\n",
    "\n",
    "    result[1] = \n",
    "    {'000':0.001, '001': 0.01, '010': 0.01, '100':0.01, '110': 0.1, '101': 0.1, '011': 0.1, '111': 0.669}\n",
    "\n",
    "Now suppose that at readout time, and with no idea what the encoded bit was, we find the result *'001'*. From the lookup tables we see that this result would occur with probability *0.1* for *encodedBit=0* and *0.01* for *encodedBit=1*. We should therefore take *decodedBit = 0*.\n",
    "\n",
    "Note that we have not taken the usual step of ignoring the logical readout, and focussing only on the abstract syndrome. Though it usually makes things simpler, it would just make things harder in this case.\n",
    "\n",
    "Note also that the lookup tables are populated by experimental data, and so decoding will suffer from numerical innacuracies when the sample size is too small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalculateError (encodedBit,results):\n",
    "    \n",
    "    # total prob of error will be caculated by looping over all strings\n",
    "    # we initialize the value to 0\n",
    "    error = 0\n",
    "    \n",
    "    # all strings that have results for the given encoded bit are looped over\n",
    "    for string in results[encodedBit].keys():\n",
    "\n",
    "        # the probability P(string|encodedBit) is extracted\n",
    "        right = results[encodedBit][string]\n",
    "        \n",
    "        # as is the probability P(string|!encodedBit)\n",
    "        # if there is no result for this value in the table, the prob is 0\n",
    "        wrong = 0\n",
    "        if string in results[(encodedBit+1)%2].keys():\n",
    "            wrong = results[(encodedBit+1)%2][string]\n",
    "\n",
    "        # if this is a string for which P(string|!encodedBit)>P(string|encodedBit), the decoding fails\n",
    "        # the probabilty P(string|encodedBit) is then added to the error\n",
    "        if (wrong>right):\n",
    "            error += right\n",
    "        # if P(string|!encodedBit)=P(string|encodedBit), the decoder randomly chooses between them\n",
    "        # P(failure|string) is therefore 0.5 in this case\n",
    "        elif (wrong==right):\n",
    "            error += 0.5*right\n",
    "        # otherwise the decoding succeeds, and we don't care about that\n",
    "            \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *GetData*\n",
    "\n",
    "For a given backend *device*, this function runs the repetition code for both possible values of the encoded bit for *totalRuns* samples with code distance from 3 to *maxSize*. The full data is then saved to file, with the file name reflecting the code distance, run and encoded bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetData(device,maxSize,totalRuns):\n",
    "    \n",
    "    # loop over code sizes that will fit on the chip (d=3 to d=8)\n",
    "    for d in range(3,maxSize+1):\n",
    "\n",
    "        print(\"**d = \" + str(d) + \"**\")\n",
    "    \n",
    "        # do the runs\n",
    "        for run in range(totalRuns):\n",
    "\n",
    "            print(\"**Run \" + str(run) + \"**\")\n",
    "\n",
    "            # get data for each encoded bit value\n",
    "            for bit in range(2):\n",
    "\n",
    "                # run the job and put results in resultsRaw\n",
    "                resultsRaw = RunRepetition(bit,d,device)\n",
    "\n",
    "                f = open('Repetition_Code_Results/'+device+'/results_d=' + str(d) + '_run=' + str(run) + '_bit=' + str(bit) + '.txt', 'w')\n",
    "                f.write( str(resultsRaw) )\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *ProcessData*\n",
    "\n",
    "For a given data set specified by *maxSize* and *totalRuns*, and an encoded bit value *encodedBit*, various probabilties are calculated.\n",
    "\n",
    "The first output contains error probabilities for codes. This is arranged as follows.\n",
    "\n",
    "* *codeResults[d-3]* gives the results for a code of distance *d*\n",
    "* *codeResults[d-3][0]* gives results for the whole code of distance *d*\n",
    "* *codeResults[d-3][k]* gives results for the effective distance *d-k* code obtained by ignoring the last *k* code qubits and ancillas\n",
    "* *codeResults[d-3][k][0]* is the error prob when decoding uses both code and ancilla qubits\n",
    "* *codeResults[d-3][k][1]* is the variance for the above\n",
    "* *codeResults[d-3][k][2]* is the error prob when decoding uses only code qubits\n",
    "* *codeResults[d-3][k][3]* is the variance for the above\n",
    "\n",
    "The second contains probabilities that single qubits across the code have value 1. This is arranged as follows.\n",
    "\n",
    "* *singleResults[d-3][j][0]* is the probability of state *1* for qubit *j* when used in a code of distance *d*\n",
    "* *singleResults[d-3][j][1]* is the variance for the above\n",
    "\n",
    "Here *j* reflects placement in the code. Qubit *c0* is *j=0*, *a0* is j=1*, etc.\n",
    "\n",
    "The third output is a collection of dictionaries *combinedResultsCode[d-3]*, one for each code distance and stored bit value. Each dictionary contains the results from the device for that case, combined over all runs. It is also truncated to show only results for bits that were code qubits. Note that the results returned are for both encoded bits, so the *encodedBit* input for the function is not used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ProcessData(device,encodedBit,maxSize,totalRuns):\n",
    "    \n",
    "    # determine whether a simulator is used\n",
    "    simulator = (device!='ibmqx3')\n",
    "    \n",
    "    \n",
    "    # initialize list used to store the calculated means and variances for results from the codes\n",
    "    codeResults = [[[0]*4 for _ in range(j)] for j in range(3,maxSize+1)]\n",
    "    singleResults = [[[0]*2 for _ in range(16)] for _ in range(3,maxSize+1)]\n",
    "    # singleResults[d-3][j][0] is the probability of state 1 for qubit j when used in a code of distance d\n",
    "    # singleResults[d-3][j][1] is the variance for the above\n",
    "    \n",
    "    \n",
    "    # the results will show that the case of partial decoding requires more analysis\n",
    "    # for this reason we will also output combinedCodeResults, which is all runs of codeResults combined\n",
    "    # here we initialize list of combined results from the code only case\n",
    "    combinedResultsCode = [[{} for _ in range(3,maxSize+1) ] for _ in range(2)]\n",
    "    \n",
    "    \n",
    "    # loop over code sizes...\n",
    "    for d in range(3,maxSize+1):    \n",
    "        # ...and the runs\n",
    "        for run in range(0,totalRuns):\n",
    "            \n",
    "            # we are going to fill a bunch of dictionaries with results\n",
    "            # each has two copies, one for each possible encoded bit\n",
    "\n",
    "            # the results that come fresh from the backend\n",
    "            resultsVeryRaw = [{} for _ in range(2)]\n",
    "            resultsRaw = [{} for _ in range(2)]\n",
    "            # the results from the full code (including ancillas)\n",
    "            # resultsFull[k] gives results for the effective distance d-k code obtained by ignoring the last k code qubits and ancillas\n",
    "            resultsFull = [[{} for _ in range(d)] for _ in range(2)]\n",
    "            # the same but with ancilla results excluded\n",
    "            resultsCode =  [[{} for _ in range(d)] for _ in range(2)]\n",
    "            # results each single bit\n",
    "            resultsSingle = [[{} for _ in range(16)] for _ in range(2)]\n",
    "\n",
    "            # we get results for both possible encoded bits\n",
    "            for bit in range(2):\n",
    "\n",
    "                # get results from file\n",
    "                f = open('Repetition_Code_Results/'+device+'/results_d=' + str(d) + '_run=' + str(run) + '_bit=' + str(bit) + '.txt')\n",
    "                resultsVeryRaw[bit] = eval(f.read())\n",
    "                f.close()\n",
    "                \n",
    "                # loop over all keys in the raw results and look at the ones without strings as values\n",
    "                # since all such entries should have a bit string as a key, we call it stringVeryRaw\n",
    "                for stringVeryRaw in resultsVeryRaw[bit].keys():\n",
    "                    if resultsVeryRaw[bit][stringVeryRaw] is not str:\n",
    "                        \n",
    "                        # create a new dictionary in which each key is padded to a bit string of length 16\n",
    "                        stringRaw = stringVeryRaw.rjust(16,'0')\n",
    "                        resultsRaw[bit][stringRaw] = resultsVeryRaw[bit][stringVeryRaw]\n",
    "\n",
    "\n",
    "                # now stringRaw only has data in the correct format\n",
    "                # let's loop over its entries and process stuff\n",
    "                for stringRaw in resultsRaw[bit].keys():\n",
    "\n",
    "                    # get the prob corresponding to this string\n",
    "                    probToAdd = resultsRaw[bit][stringRaw]\n",
    "\n",
    "                    # first we deal with resultsFull and resultsCode\n",
    "\n",
    "                    # loop over all truncated codes relevant for this d\n",
    "                    for k in range(d):\n",
    "                        # distance of this truncated code\n",
    "                        dd = d-k\n",
    "\n",
    "                        # extract the bit string relevant for resultsFull\n",
    "                        # from left to right this will alternate between code and ancilla qubits in increasing order\n",
    "                        stringFull = ''\n",
    "                        for codeQubit in range(dd): # add bit value for a code qubit...\n",
    "                            stringFull += stringRaw[15-GetAddress(codeQubit,0,simulator)]\n",
    "                            if (codeQubit!=(d-1)): #...and then the ancilla next to it (if we haven't reached the end of the code)\n",
    "                                stringFull += stringRaw[15-GetAddress(codeQubit,1,simulator)]\n",
    "\n",
    "                        # remove ancilla bits from this to get the string for resultsCode\n",
    "                        stringCode = \"\"\n",
    "                        for n in range(dd):\n",
    "                            stringCode += stringFull[2*n]\n",
    "\n",
    "                        AddProbToResults(probToAdd,stringFull,resultsFull[bit][k])\n",
    "                        AddProbToResults(probToAdd,stringCode,resultsCode[bit][k])\n",
    "\n",
    "                    # now we'll do results single\n",
    "\n",
    "                    # the qubits are listed in the order they are in the code\n",
    "                    # so for each code qubit\n",
    "                    for jj in range(8):\n",
    "                        # loop over it and its neighbour\n",
    "                        for offset in range(2):\n",
    "                            stringSingle = stringRaw[15-GetAddress(jj,offset,simulator)]\n",
    "                            AddProbToResults(probToAdd,stringSingle,resultsSingle[bit][2*jj+offset])\n",
    "\n",
    "                # combined this run's resultsCode with the total, using the k=0 values\n",
    "                for stringCode in resultsCode[bit][0].keys():\n",
    "                    probToAdd = resultsCode[bit][0][stringCode]/10\n",
    "                    AddProbToResults(probToAdd,stringCode,combinedResultsCode[bit][d-3])\n",
    "        \n",
    "\n",
    "            # initialize list used to store the calculated means and variances for results from the codes\n",
    "            codeSample = [[0]*2 for _ in range(d)]\n",
    "            # here\n",
    "            # codeSample gives the results\n",
    "            # codeSample[0] gives results for the whole code\n",
    "            # codeSample[k] gives results for the effective distance d-k code obtained by ignoring the last k code qubits and ancillas\n",
    "            # codeSample[k][0] is the error prob when decoding uses both code and ancilla qubits\n",
    "            # codeSample[k][1] is the error prob when decoding uses only code qubits\n",
    "            singleSample = [0]*16\n",
    "            # singleSample[j] is the probability of state 1 for qubit j when the required bit value is encoded\n",
    "\n",
    "            # write results in            \n",
    "            for k in range(d):\n",
    "                codeSample[k][0] = CalculateError(encodedBit,[resultsFull[0][k],resultsFull[1][k]])\n",
    "                codeSample[k][1] = CalculateError(encodedBit,[resultsCode[0][k],resultsCode[1][k]])\n",
    "            for j in range(16):\n",
    "                if '1' in resultsSingle[encodedBit][j].keys():\n",
    "                    singleSample[j] = resultsSingle[encodedBit][j]['1']\n",
    "            \n",
    "            \n",
    "            # add results from this run to the overall means and variances\n",
    "            for k in range(d):\n",
    "                for l in range(2):\n",
    "                    codeResults[d-3][k][2*l] += codeSample[k][l] / totalRuns # means\n",
    "                    codeResults[d-3][k][2*l+1] += codeSample[k][l]**2 / totalRuns # variances\n",
    "            for j in range(16):\n",
    "                singleResults[d-3][j][0] += singleSample[j] / totalRuns\n",
    "                singleResults[d-3][j][1] += singleSample[j]**2 / totalRuns\n",
    "\n",
    "        # finish the variances by subtracting the square of the mean\n",
    "        for k in range(d):\n",
    "            for l in range(1,4,2):\n",
    "                codeResults[d-3][k][l] -= codeResults[d-3][k][l-1]**2\n",
    "        for j in range(16):\n",
    "                singleResults[d-3][j][1] -= singleResults[d-3][j][0]**2\n",
    "\n",
    "    \n",
    "    # return processed results                                                                                                                        \n",
    "    return codeResults, singleResults, combinedResultsCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *MakeGraph*\n",
    "\n",
    "Plots the sets of data in *Y* with error bars given by the corresponding variances in *y*. Values for the X axis are in *X*. Labels for x axis and y axis are in *axisLabel*. Labels for the legend can be supplied in *labels*, though there is no legend by default. The position can be supplied in *legendPos*. It is upper right be default. The numbers can be printed to screen using *verbose=True* and the graph can be made logarithmic on the y axis using *log=True*. Both these are off by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first a quick function to do logs in a nice way\n",
    "def Log (x):\n",
    "    if (x>0):\n",
    "        y = math.log( x , 10 )\n",
    "    else:\n",
    "        y = math.nan # the input would cause a domain error, we output a nan    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeGraph(X,Y,y,axisLabel,labels=[],legendPos='upper right',verbose=False,log=False):\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 30})\n",
    "    \n",
    "    # if verbose, print the numbers to screen\n",
    "    if verbose==True:\n",
    "        print(\"\\nX values\")\n",
    "        print(X)\n",
    "        for j in range(len(Y)):\n",
    "            print(\"\\nY values for series \"+str(j))\n",
    "            print(Y[j])\n",
    "            print(\"\\nError bars\")\n",
    "            print(y[j])\n",
    "            print(\"\")\n",
    "    \n",
    "    # convert the variances of varY into widths of error bars\n",
    "    for j in range(len(y)):\n",
    "        for k in range(len(y[j])):\n",
    "            y[j][k] = math.sqrt(y[j][k]/2)\n",
    "            if log==True:\n",
    "                yp = Log(Y[j][k]+y[j][k]) - Log(Y[j][k])\n",
    "                if (Y[j][k]-y[j][k]>0):\n",
    "                    ym = Log(Y[j][k]) - Log(Y[j][k]-y[j][k])\n",
    "                else:\n",
    "                    ym = 0\n",
    "                y[j][k] = max(yp,ym)\n",
    "    \n",
    "    # if a log plot, do the logs\n",
    "    if log==True:\n",
    "        for j in range(len(Y)):\n",
    "            for k in range(len(Y[j])):\n",
    "                Y[j][k] = Log(Y[j][k])\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    \n",
    "    # add in the series\n",
    "    for j in range(len(Y)):\n",
    "        if labels==[]:\n",
    "            plt.errorbar(X, Y[j], marker = \"x\", markersize=20, yerr = y[j], linewidth=5)\n",
    "        else:\n",
    "            plt.errorbar(X, Y[j], label=labels[j], marker = \"x\", markersize=20, yerr = y[j], linewidth=5)\n",
    "    \n",
    "    plt.legend(loc=legendPos)\n",
    "    \n",
    "    # label the axes\n",
    "    plt.xlabel(axisLabel[0])\n",
    "    plt.ylabel(axisLabel[1])\n",
    "    \n",
    "    # make sure X axis is fully labelled\n",
    "    plt.xticks(X)\n",
    "\n",
    "    # make the graph\n",
    "    plt.show()\n",
    "    \n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4 - Results\n",
    "\n",
    "\n",
    "We will see how well the repetition code works for *d* from *3* to *8*.\n",
    "\n",
    "For each code of distance *d*, the probability for a logical error is calculated given each possible bit value that can be encoded. This is done for the case of **full decoding**, in which the full results of the code are used (from both code qubits and ancilla qubits) and for **partial decoding** in which the ancilla results are ignored and only the results of the code qubits are used.\n",
    "\n",
    "The same is also done for truncated codes of distance *dd=d-k*. For example, consider the *d=5* code\n",
    "\n",
    "    c0--a0--c1--a1--c2--a2--c3--a3--c4\n",
    "    \n",
    "If the results of *a3* and *c4* were ignored, the decoding would effectively be the same as that of the *d=3* code\n",
    "\n",
    "    c0--a0--c1--a1--c2--a2--c3\n",
    "    \n",
    "The difference between this truncated code and the true *d=3* code is that the former has additional noise coming from the additional CNOTs of the *d=5* code. Considering these truncated code gives us another perspective on how error suppression changes as code distance is increased.\n",
    "\n",
    "The probability of a qubit being in state *1* is also determined for every qubit on the code at the end of the circuit. This will give us an idea of how well qubits are holding to their encoded values. The qubit located next to the code is used for a single qubit encoding. The results for this will therefore allow us to see how well a many qubit encoding compares against a single qubit one.\n",
    "\n",
    "For successfully working repetition codes, we would expect results to show the following for each *d*.\n",
    "\n",
    "1) The logical error probability for the code the after full decoding should be significantly less than that for the single qubit encoding.\n",
    "\n",
    "2) It must also be significantly greater than that for after partial decoding.\n",
    "\n",
    "3) Each code should have lower logical error probabilities (for full and partial decoding) than the truncated codes derived from them.\n",
    "\n",
    "Condition (1) ensures that using a code actually provides better protection against errors than just using a single qubit for each bit. Condition (2) ensures that the ancilla assisted measurements actually provide useful information for the decoding. If they did not, the entangling gates would essentially just be another source of noise, rather than a useful quantum operation.\n",
    "\n",
    "When running the following, you will be asked if you want to look at the real device or a simulator. You'll then be asked if you have pre-existing data. If not, new data will be generated.\n",
    "\n",
    "Note that the numerical data can be printed for the following plots by adding *verbose=True* to the corresponding call to *MakeGraph*. The plots can be given a logarithmic y axis using *log=True*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to use\n",
    "# this also sets the maximum d. We only go up to 6 on the simulator\n",
    "userInput = input(\"Do you want results for the real device? (input Y or N) If not, results will be from a simulator. \\n\").upper()\n",
    "if (userInput==\"Y\"):\n",
    "    device = 'ibmqx3'\n",
    "    maxSize = 8\n",
    "else:\n",
    "    device = 'local_qasm_simulator'\n",
    "    maxSize = 6\n",
    "\n",
    "\n",
    "# determine whether data needs to be taken\n",
    "userInput = input(\"Do you want to process saved data? (Y/N) If not, new data will be obtained. \\n\").upper()\n",
    "if (userInput==\"Y\"):\n",
    "    dataAlready = True\n",
    "else:\n",
    "    dataAlready = False\n",
    "\n",
    "# set number of runs used for stats\n",
    "totalRuns = 10 # should be 10\n",
    "\n",
    "# if we need data, we get it\n",
    "if (dataAlready==False):\n",
    "\n",
    "    # get the required data for the desired number of runs\n",
    "    GetData(device,maxSize,totalRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codeResults = [[],[]]\n",
    "singleResults = [[],[]]\n",
    "for encodedBit in range(2):\n",
    "    codeResults[encodedBit], singleResults[encodedBit], combinedResultsCode = ProcessData(device,encodedBit,maxSize,totalRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following six plots are for codes of distance *d=3* to *d=8*. Each has two series, one for an encoded *0* and one for an encoded *1*. The plots show the probability that each qubit in the chip is measured to be in state *1* at the end of the process.\n",
    "\n",
    "In the ideal case, we would expect this probability to be zero in all cases for an encoded *0*. For an encoded *1*, it should be zero for all ancilla and unused qubits, and one for the code qubits. It should also be one for the single qubit used to encode a logical qubit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot for single qubit data for each code distance\n",
    "for d in range(3,maxSize+1):\n",
    "    X = range(16)\n",
    "    Y = []\n",
    "    y = []\n",
    "    # a series for each encoded bit\n",
    "    for encodedBit in range(2):        \n",
    "        Y.append([singleResults[encodedBit][d-3][j][0] for j in range(16)])\n",
    "        y.append([singleResults[encodedBit][d-3][j][1] for j in range(16)])\n",
    "    # make graph\n",
    "    print(\"\\n\\n***Final state of each qubit for code of distance d = \" + str(d) + \"***\")\n",
    "    MakeGraph(X,Y,y,['Qubit position in code','Probability of 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following four graphs show logical error probability plotted against effective code distance. The cases they consider are (in order):\n",
    "\n",
    "* Stored 0, full decoding;\n",
    "* Stored 0, partial decoding;\n",
    "* Stored 1, full decoding;\n",
    "* Stored 1, partial decoding.\n",
    "\n",
    "The six series in each represent data from codes of different sizes. The rightmost data point for each is the logical error probability when the full code is used, and so the effective code distance is *d*. The point for effective code distance *d-1* is calculated from the same data, but with the final code and ancilla qubits ignored to effectively lower the code distance. The rest of the points are obtained by repeating this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for encodedBit in range(2): # separate plots for each encoded bit\n",
    "    for decoding in ['full','partial']:\n",
    "        dec = (decoding=='partial') # this is treated as 0 if full and 1 if partial\n",
    "        X = range(1,maxSize+1)\n",
    "        Y = []\n",
    "        y = []\n",
    "        for d in range(3,maxSize+1):# series for each code size\n",
    "            seriesY = [math.nan]*(maxSize)\n",
    "            seriesy = [math.nan]*(maxSize)\n",
    "            for k in range(d):\n",
    "                seriesY[d-k-1] = codeResults[encodedBit][d-3][k][2*dec+0]\n",
    "                seriesy[d-k-1] = codeResults[encodedBit][d-3][k][2*dec+1]\n",
    "            Y.append(seriesY)\n",
    "            y.append(seriesy)\n",
    "        labels = ['d=3','d=4','d=5','d=6','d=7','d=8']\n",
    "        MakeGraph(X,Y,y,['Effective code distance','Logical error probability'],\n",
    "                  labels=labels,legendPos = 'upper right')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two plots are for an encoded logical *0* and logical *1*, respectively. They show the probability of a logical error for (non-truncated) codes of various sizes. The two series in each represent full decoding (using both code and ancilla qubits) and partial decoding (using only code qubits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for encodedBit in range(2): # separate plots for each encoded bit\n",
    "    X = range(3,maxSize+1)\n",
    "    Y = []\n",
    "    y = []\n",
    "    for decoding in ['full','partial']:\n",
    "        dec = (decoding=='partial') # this is treated as 0 if full and 1 if partial\n",
    "        Y.append([codeResults[encodedBit][d-3][0][2*dec+0] for d in range(3,maxSize+1)])\n",
    "        y.append([codeResults[encodedBit][d-3][0][2*dec+1] for d in range(3,maxSize+1)])\n",
    "    MakeGraph(X,Y,y,['Code distance, d','Error probability, P'],\n",
    "              labels=['Full decoding','Partial decoding'],legendPos='upper right')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graphs focus on the case of partial decoding. They look at the probabilities for different kinds of errors on the code qubits, as well as the way in in which the decoding is performed.\n",
    "\n",
    "When doing this we will combine the data from all 10 runs, to get a single data set that is cleaner than all the others. This will mean a lack of error bars, but we know what kind of values these would give from previous plots.\n",
    "\n",
    "In this analysis, we will use the fact that it is pretty much just the number of *0*s and *1*s in a result that is important, and not their placement. So we'll look at the probability for each number of *1*s.\n",
    "\n",
    "We'll plot this in two ways for each code distance. First we'll plot the number probability for each number of errors. For example, *00000* would have no errors in the case that *0* was stored, but five if *1* was stored. We would expect to see the probability decrease with the number of errors for both stored *0* and stored *1*.\n",
    "\n",
    "We will then plot the number of *1*s. For stored *0*, this corresponds to the number of errors, and so we would expect it to decrease. For stored *1* it is the opposite, since no *1*s is the case of maximum error. The probability should therefore increase for this data. There will therefore be a crossover point for the number of *1*s, which explictly tells us something about decoding. If the number of *1*s in a given result is below the crossover point, the most likely encoded value is *0*. Above the crossover point, the most likely value is *1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for each code distance and each encoded bit value, we'll create a list of the probabilities for each possible number of errors\n",
    "# list is initialized with zeros\n",
    "errorNum = [[[0]*(d+1) for d in range(3,maxSize+1)] for _ in range(2)]\n",
    "\n",
    "for d in range(3,maxSize+1):\n",
    "        for bit in range(2):\n",
    "            # for each code distance and each encoded bit value we look at all possible result strings\n",
    "            for string in combinedResultsCode[bit][d-3]:\n",
    "                # count the number of errors in each string\n",
    "                num = 0\n",
    "                for j in range(d):\n",
    "                    num += ( int( string[j] , 2 ) + bit )%2\n",
    "                # add prob to corresponding number of errors\n",
    "                errorNum[bit][d-3][num] += combinedResultsCode[bit][d-3][string]\n",
    "        \n",
    "\n",
    "        # the we make a graph for each, and print a title\n",
    "        X0 = copy.copy(errorNum[0][d-3]) \n",
    "        X1 = copy.copy(errorNum[1][d-3]) # the lists given to MakeGraph can get altered, so we don't put errorNum itself in\n",
    "        print(\"\\n\\n***Probability of errors on code qubits for d = \" + str(d) + \"***\")\n",
    "        MakeGraph(range(d+1),[X0,X1],[[0]*(d+1)]*2,['Number of code qubit errors','Probability (log base 10)'],\n",
    "                  labels=['Encoded 0','Encoded 1'],legendPos='upper right',log=True)\n",
    "\n",
    "        # actually, we make two graphs. This one plots the number of 1s rather than errors, and so the plot for encoded 1 is inverted\n",
    "        X0 = copy.copy(errorNum[0][d-3]) # X0 in this graph is as before\n",
    "        X1 = copy.copy(errorNum[1][d-3])[::-1] # but X1 has its order inverted\n",
    "        print(\"\\n\\n***Probability for number of 1s in code qubit result for d = \" + str(d) + \"***\")\n",
    "        MakeGraph(range(d+1),[X0,X1],[[0]*(d+1)]*2,['Number of 1s in code qubit result','Probability (log base 10)'],\n",
    "                  labels=['Encoded 0','Encoded 1'],legendPos='center right',log=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
